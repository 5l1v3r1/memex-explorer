User's Guide to Memex Explorer
------------------------------

*NOTE: Memex Explorer is still under active development, and this guide is
constantly evolving as a result. For documentation requests, please*
`file an issue <https://github.com/memex-explorer/memex-explorer/issues>`_
*and we will endeavor to address it as soon as possible.*

Application Structure
=====================

Memex Explorer is a web application that registers *microservices*. Each
microservice provides a specific functionalityâ€”at present, these include:

Crawl Space
  A microservice to create, run, and analyze `Nutch <http://nutch.apache.org/>`_
  and `ACHE <https://github.com/ViDA-NYU/ache>`_ crawls. The crawl operation
  is heavily abstracted and simplified. Users provide a list of seed URLs to
  start the crawl, and in the case of ACHE's targeted crawling,
  a machine learning `model <https://github.com/ViDA-NYU/ache#build-a-model-for-aches-page-classifier>`_ to declare the relevancy of crawled pages.

Image Space
  A microservice for the display and searching of images and their associated
  metadata. As a basic example of microservice interoperation,
  users will be able to dump images from Nutch crawls into an Image Space
  for analysis. Users can also search for images that match on the registered
  camera serial number, as well as upload their own images into an
  Image Space for comparison.

Home Page
=========

The landing page lists currently registered projects. All microservice features
are connected to, and accessed through, a given project. To create a project,
click on the "New Project" button.

.. image:: _static/img/homepage-view.png

Project Page
============

The project page lists actions provided by registered microservices. Click
on the gear icon to change the project name or description.

In the current Memex Explorer, only the Crawl Space microservice
has been registered. Therefore, each project page will list the current
crawls and crawl models.

.. image:: _static/img/project-page.png

Registering a Crawl Model
=========================

ACHE crawls require a *Crawl Model* to power the page classifier.
The model consists of two elements: a "model" file and "features" file. These
can be generated by following the `instructions <https://github.com/ViDA-NYU/ache#build-a-model-for-aches-page-classifier>`_ on the ACHE GitHub page.

To register a new crawl model, click on the '+' icon in the Crawl Models header.
This will take you to the crawl model registration page.

.. image:: _static/img/add-crawl-model.png

Registering a Crawl
===================

To register a new crawl, click the '+' icon in the Crawls header. This will
take you to the crawl registration page.

.. image:: _static/img/add-crawl.png

For Nutch crawls, you will need to provide a name, a description, and a seeds
list text file containing newline-delimited URLs.

For ACHE crawls, you will need to provide the same inputs as above, and
further select a Crawl Model.



